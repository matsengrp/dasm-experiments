{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wang 2023 dataset\n",
    "\n",
    "Dataset curated by the Kleinstein group and available on their [Bitbucket](https://bitbucket.org/kleinstein/projects/src/master/Wang2023/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarding rows with total_len > 300. There is 1\n",
      "(12430, 9)\n",
      "(3107, 9)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from dnsmex.local import localify\n",
    "from netam.framework import load_crepe\n",
    "import dnsmex.wang2023_helper as helper\n",
    "from dnsmex.ablang_wrapper import AbLangWrapper\n",
    "\n",
    "\n",
    "data_dir = localify(\"DATA_DIR/Wang2023/data\")\n",
    "\n",
    "# Load and prepare the dataset\n",
    "wang_df, max_seq_len = helper.filtered_wang_specificity(data_dir)\n",
    "\n",
    "# wang_df = wang_df.sample(1000).reset_index(drop=True)\n",
    "train_df = wang_df.sample(frac=0.8, random_state=42)\n",
    "test_df = wang_df.drop(train_df.index)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for DASM 1M (jaffeCC+tangCC). Shape: torch.Size([12430, 128])\n",
      "Generated embeddings for DASM 4M (jaffeCC+tangCC-joint). Shape: torch.Size([12430, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matsen/re/netam/.venv/lib/python3.11/site-packages/ablang2/load_model.py:112: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\n",
      "Running seqcoding: 100%|██████████| 125/125 [10:24<00:00,  5.00s/it]\n",
      "Running seqcoding: 100%|██████████| 32/32 [02:33<00:00,  4.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for AbLang seqcoding. Shape: torch.Size([12430, 480])\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "DASM 1M (jaffeCC+tangCC)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "DASM 4M (jaffeCC+tangCC-joint)",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "AbLang seqcoding",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "36439bd7-4f19-449a-b961-1e27741e36f9",
       "rows": [
        [
         "embedding_dim",
         "128",
         "256",
         "480"
        ],
        [
         "train_auroc",
         "0.904",
         "0.911",
         "0.936"
        ],
        [
         "test_auroc",
         "0.854",
         "0.852",
         "0.899"
        ],
        [
         "train_auprc",
         "0.912",
         "0.921",
         "0.938"
        ],
        [
         "test_auprc",
         "0.856",
         "0.858",
         "0.887"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DASM 1M (jaffeCC+tangCC)</th>\n",
       "      <th>DASM 4M (jaffeCC+tangCC-joint)</th>\n",
       "      <th>AbLang seqcoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>embedding_dim</th>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auroc</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auroc</th>\n",
       "      <td>0.854</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_auprc</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_auprc</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DASM 1M (jaffeCC+tangCC) DASM 4M (jaffeCC+tangCC-joint)  \\\n",
       "embedding_dim                      128                            256   \n",
       "train_auroc                      0.904                          0.911   \n",
       "test_auroc                       0.854                          0.852   \n",
       "train_auprc                      0.912                          0.921   \n",
       "test_auprc                       0.856                          0.858   \n",
       "\n",
       "              AbLang seqcoding  \n",
       "embedding_dim              480  \n",
       "train_auroc              0.936  \n",
       "test_auroc               0.899  \n",
       "train_auprc              0.938  \n",
       "test_auprc               0.887  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize container for all results\n",
    "all_results = {}\n",
    "\n",
    "def train_and_evaluate_binding_predictor(\n",
    "    train_embeddings, \n",
    "    test_embeddings, \n",
    "    train_binds,\n",
    "    test_binds,\n",
    "    random_state=42\n",
    "):\n",
    "    \"\"\"Train an SVM classifier on embeddings to predict binding.\n",
    "    \n",
    "    Args:\n",
    "        train_embeddings: Numpy array of shape (n_train, n_features)\n",
    "        test_embeddings: Numpy array of shape (n_test, n_features) \n",
    "        train_binds: Binary labels for training data\n",
    "        test_binds: Binary labels for test data\n",
    "        random_state: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing model, scaler, and performance metrics\n",
    "    \"\"\"\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(train_embeddings)\n",
    "    X_test_scaled = scaler.transform(test_embeddings)\n",
    "\n",
    "    # Train SVM\n",
    "    model = SVC(\n",
    "        kernel='rbf',\n",
    "        random_state=random_state,\n",
    "        probability=True,  # Enable probability estimates\n",
    "        class_weight='balanced'  # Handle potential class imbalance\n",
    "    )\n",
    "    model.fit(X_train_scaled, train_binds)\n",
    "\n",
    "    # Get predictions\n",
    "    y_train_pred = model.predict_proba(X_train_scaled)[:, 1]\n",
    "    y_test_pred = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Calculate metrics\n",
    "    results = {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'train_auroc': roc_auc_score(train_binds, y_train_pred),\n",
    "        'test_auroc': roc_auc_score(test_binds, y_test_pred),\n",
    "        'train_auprc': average_precision_score(train_binds, y_train_pred),\n",
    "        'test_auprc': average_precision_score(test_binds, y_test_pred),\n",
    "        'embedding_dim': train_embeddings.shape[1]\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "def evaluate_dasm_model(model_path, model_name):\n",
    "    \"\"\"Evaluate a DASM model.\"\"\"\n",
    "    crepe = load_crepe(localify(model_path))\n",
    "    \n",
    "    def mean_rep_of(df):\n",
    "        seqs = df[[\"heavy\", \"light\"]].values.tolist()\n",
    "        rep = crepe.represent_sequences(seqs)\n",
    "        mean_rep = [rep.mean(axis=0) for rep in rep]\n",
    "        return torch.stack(mean_rep)\n",
    "    \n",
    "    train_mean_rep = mean_rep_of(train_df)\n",
    "    test_mean_rep = mean_rep_of(test_df)\n",
    "    \n",
    "    print(f\"Generated embeddings for {model_name}. Shape: {train_mean_rep.shape}\")\n",
    "    \n",
    "    train_mean_rep_array = train_mean_rep.numpy()\n",
    "    test_mean_rep_array = test_mean_rep.numpy()\n",
    "    \n",
    "    results = train_and_evaluate_binding_predictor(\n",
    "        train_mean_rep_array,\n",
    "        test_mean_rep_array,\n",
    "        train_df[\"binds\"],\n",
    "        test_df[\"binds\"]\n",
    "    )\n",
    "    \n",
    "    all_results[model_name] = results\n",
    "    return results\n",
    "\n",
    "def evaluate_ablang():\n",
    "    \"\"\"Evaluate AbLang.\"\"\"\n",
    "    model_name = \"AbLang seqcoding\"\n",
    "    ablang_wrapper = AbLangWrapper()\n",
    "    \n",
    "    def seqcoding_of(df):\n",
    "        seqs = df[[\"heavy\", \"light\"]].values.tolist()\n",
    "        return ablang_wrapper.seqcoding(seqs)\n",
    "    \n",
    "    train_mean_rep = seqcoding_of(train_df)\n",
    "    test_mean_rep = seqcoding_of(test_df)\n",
    "    \n",
    "    print(f\"Generated embeddings for {model_name}. Shape: {train_mean_rep.shape}\")\n",
    "    \n",
    "    train_mean_rep_array = train_mean_rep.numpy()\n",
    "    test_mean_rep_array = test_mean_rep.numpy()\n",
    "    \n",
    "    results = train_and_evaluate_binding_predictor(\n",
    "        train_mean_rep_array,\n",
    "        test_mean_rep_array,\n",
    "        train_df[\"binds\"],\n",
    "        test_df[\"binds\"]\n",
    "    )\n",
    "    \n",
    "    all_results[model_name] = results\n",
    "    return results\n",
    "\n",
    "# Run evaluations for each model\n",
    "# First DASM model\n",
    "evaluate_dasm_model(\n",
    "    \"DASM_GRID_DIR/dasm_1m-v1jaffeCC+v1tangCC-mh-0\", \n",
    "    \"DASM 1M (jaffeCC+tangCC)\"\n",
    ")\n",
    "\n",
    "# Second DASM model\n",
    "evaluate_dasm_model(\n",
    "    \"DASM_TRAINED_MODELS_DIR/dasm_4m-v1jaffeCC+v1tangCC-joint\",\n",
    "    \"DASM 4M (jaffeCC+tangCC-joint)\"\n",
    ")\n",
    "\n",
    "# AbLang model\n",
    "evaluate_ablang()\n",
    "\n",
    "# Convert results to DataFrame for easy viewing\n",
    "def create_results_df(results_dict):\n",
    "    metrics = ['embedding_dim', 'train_auroc', 'test_auroc', 'train_auprc', 'test_auprc']\n",
    "    results_df = pd.DataFrame(index=metrics)\n",
    "    \n",
    "    for model_name, result in results_dict.items():\n",
    "        model_results = {\n",
    "            'embedding_dim': result['embedding_dim'],\n",
    "            'train_auroc': f\"{result['train_auroc']:.3f}\",\n",
    "            'test_auroc': f\"{result['test_auroc']:.3f}\",\n",
    "            'train_auprc': f\"{result['train_auprc']:.3f}\",\n",
    "            'test_auprc': f\"{result['test_auprc']:.3f}\"\n",
    "        }\n",
    "        results_df[model_name] = pd.Series(model_results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Display results table\n",
    "results_df = create_results_df(all_results)\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
